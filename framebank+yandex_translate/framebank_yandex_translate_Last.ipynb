{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53752a4f-6d99-4760-a8db-26ff41e66928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14e0ede6-e860-4564-8992-afcda163853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf7af7ec-65a5-4b5e-9f0b-2bc7804136c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "from pprint import pprint as print_\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from isanlp_srl_framebank.pipeline_default import PipelineDefault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2dce71b-7cb5-479b-b824-5e317ba4eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de29404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   343  100   254  100    89   1646    576 --:--:-- --:--:-- --:--:--  2241\n"
     ]
    }
   ],
   "source": [
    "!curl -d \"{\\\"yandexPassportOauthToken\\\":\\\"y0_AgAAAAAFAhuyAATuwQAAAADTA2uLt9P4wIhIRcycxMNG36QNKa9u_pc\\\"}\" \"https://iam.api.cloud.yandex.net/iam/v1/tokens\" --ssl-no-revoke -o iamToken.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ab5b8cd-836f-4a51-a1f6-970fbc58364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('iamToken.txt') as f:\n",
    "    d = json.loads(f.read())\n",
    "    IAM_TOKEN = d['iamToken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc4d435d-dd7e-4551-bdeb-9d3922761eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t1.9euelZqKnZTNjJjOls2KzJrHyZjLzO3rnpWam46Pjp6Qj5uam5KQxo_Pxo3l8_d-S31i-e9lYnse_t3z9z56emL572Viex7-.jZDcaxR3usftEs2ygIlUYe4XlKol5rpaeF3nuPWw2MQCa6nd-ivVIa1-VxUUO3v7PWUN3Ouj9rkocZ76U5m4Ag'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IAM_TOKEN = 't1.9euelZqaz5DGjI6Py5bLnoqTlo_Oju3rnpWaj46Nkc6ejZaLyZvOmZqWj53l8_dIF2Zk-e9eDic9_t3z9whGY2T5714OJz3-.1UJE5innTD10cDR2-7YbCzvwem5VKOvoIQCksQwLbJAA7oAdm4OpX9lgQyC6cosbkLvAMqxKaFT1SfQlDXTlBg'\n",
    "folder_id = 'b1grvnc3e8sgtm7qcsja'\n",
    "IAM_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0645e314-9eb8-48f3-aea0-e39668c6c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run --rm -p 3333:3333 inemo/isanlp\n",
    "# docker run --rm --shm-size=1024m -ti -p 3334:9999 inemo/syntaxnet_rus server 0.0.0.0 9999\n",
    "# docker run --rm -p 3335:3333 inemo/isanlp_srl_framebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a25271b1-4aa5-427a-b82f-ea30a173cf62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from isanlp_srl_framebank.pipeline_default import PipelineDefault  \n",
    "#\n",
    "ppl = PipelineDefault(address_morph=('localhost', 3333),\n",
    "                      address_syntax=('localhost', 3334),\n",
    "                      address_srl=('localhost', 3335))\n",
    "res = ppl('Мы поехали на дачу.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f94b6ca7-3646-4b30-87e8-b80c441494ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 5.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "languages = ['tat', 'kaz', 'kir', 'bak', 'uzb'] # языки татарский, казахский, киргизский\n",
    "language = languages[0]\n",
    "url = 'https://beta.apertium.org/index.eng.html#analysis?aLang=' + language + '&aQ='    \n",
    "browser = webdriver.Chrome()\n",
    "browser.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4614738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_srl2:\n",
    "    def __init__(self, RUS_SENTENCE=None):\n",
    "        self.RUS_SENTENCE = RUS_SENTENCE\n",
    "        self.ppl = PipelineDefault(address_morph=('localhost', 3333),\n",
    "                      address_syntax=('localhost', 3334),\n",
    "                      address_srl=('localhost', 3335))\n",
    "        self.language_code_dict =  {\n",
    "        'татарский': ['tt', 'Tatar'],\n",
    "        'казахский' : ['kk', 'Kazakh'],\n",
    "        'башкирский': ['ba', 'Bashqort'],\n",
    "        'киргизский' : ['ky', 'Kyrgyz']\n",
    "        }\n",
    "\n",
    "    def translation(self, texts, source_language='tt', target_language='ru'):\n",
    "        #print('texts', texts)\n",
    "        body = {\n",
    "            \"targetLanguageCode\": target_language,\n",
    "            \"texts\": texts,\n",
    "            \"folderId\": folder_id,\n",
    "            \"sourceLanguageCode\":  source_language\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer {0}\".format(IAM_TOKEN)\n",
    "        }\n",
    "        url = 'https://translate.api.cloud.yandex.net/translate/v2/translate'\n",
    "        response = requests.post(url,\n",
    "            json = body,\n",
    "            headers = headers\n",
    "        )\n",
    "        if response.status_code != 200:\n",
    "            print('Ожидаю 0.5 секунды...')  \n",
    "            time.sleep(0.5)\n",
    "            response = requests.post(url,\n",
    "            json = body,\n",
    "            headers = headers\n",
    "            )\n",
    "        d = json.loads(response.text)\n",
    "        #print(texts, d)\n",
    "        translations = d['translations']\n",
    "#         print([t['text'] for t in translations])\n",
    "        return [t['text'] for t in translations]\n",
    "    \n",
    "    def drop_punkt(self, word):\n",
    "        punc = '''!()-[]{};:\"\\,<>./?@#$%^&*_~'''\n",
    "        for p in punc:\n",
    "            word = word.replace(p,'')\n",
    "        return word\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        words = text.split()\n",
    "        return [self.drop_punkt(word) for word in words]\n",
    "    \n",
    "    def get_morph(self, text, language):\n",
    "        lang_field = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[1]/div/select')\n",
    "        lang_field.send_keys(language)\n",
    "\n",
    "        text_field = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[2]/div/textarea').clear()\n",
    "        text_field = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[2]/div/textarea')\n",
    "\n",
    "        text = self.drop_punkt(text)\n",
    "        text_field.send_keys(text)\n",
    "\n",
    "        button = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[3]/div/button')\n",
    "        button.click()\n",
    "        sleep(1)\n",
    "\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        translation = soup.find_all('td',class_=\"text-left\")\n",
    "        words = []\n",
    "        for word in translation:\n",
    "            word = word.text.split()\n",
    "            for i, w in enumerate(word):\n",
    "                if w == '↤':\n",
    "                    break\n",
    "            word = word[:i]\n",
    "            for w in word:\n",
    "                words.append(w)\n",
    "        return words\n",
    "\n",
    "\n",
    "    def print_roles(self, lemma, role_annot, targetLanguage=None):\n",
    "        roles = []\n",
    "        for sent_num, ann_sent in enumerate(role_annot):\n",
    "            word_role = {}\n",
    "            \n",
    "            for event in ann_sent:\n",
    "#                 print(event.pred)\n",
    "                lemma_pred = lemma[sent_num][event.pred[0]]\n",
    "#                 print(lemma_pred)\n",
    "                if targetLanguage is not None:\n",
    "                    trg_lang = self.language_code_dict[targetLanguage][0]\n",
    "                    src_lang = 'ru'\n",
    "                    #print('=====Pred: {}'.format(self.translation(lemma_pred, src_lang, trg_lang)[0]))\n",
    "                    word_role['V'] = self.translation(lemma_pred, src_lang, trg_lang)\n",
    "                else:\n",
    "                    print('=====Pred: {}'.format(lemma_pred))\n",
    "                for arg in event.args:\n",
    "                    lemma_arg  = lemma[sent_num][arg.begin]\n",
    "                    if targetLanguage is not None:\n",
    "                        #print('Arg({}): {}'.format(arg.tag, self.translation(lemma_arg, src_lang, trg_lang)[0]))\n",
    "                        word_role['Arg({})'.format(arg.tag)] = self.translation(lemma_arg, src_lang, trg_lang)\n",
    "                    else:\n",
    "                        print('Arg({}): {}'.format(arg.tag, lemma_arg))\n",
    "            roles.append(word_role)\n",
    "        return roles\n",
    "    \n",
    "    def get_srl_turkic(self, rus_text, selected_language):\n",
    "        res = ppl(rus_text)\n",
    "        return self.print_roles(res['lemma'], res['srl'], selected_language)\n",
    "        \n",
    "    def get_tags(self, words, srl_verb):\n",
    "        new_tags = []\n",
    "        for word in words:\n",
    "            for srl in srl_verb.keys(): \n",
    "                if self.drop_punkt(word) in srl_verb[srl]:\n",
    "                    role = srl\n",
    "                    break\n",
    "                else:\n",
    "                    role = 'O'\n",
    "            new_tags.append(role)\n",
    "        return new_tags\n",
    "\n",
    "    def get_new_roles(self, tat_sentence, morph_sentence, roles, words):\n",
    "        result = {'verbs': []}\n",
    "        metric = []\n",
    "        for verb in roles:\n",
    "            new_roles = {}\n",
    "            srl_verb = {'verb':''}\n",
    "#             print(verb)\n",
    "            for srl in verb.keys():\n",
    "    #             morph = get_morph(verb[srl], language)[0]\n",
    "                morph = verb[srl][0]\n",
    "#                 print(morph)\n",
    "        #         Ищем слово в предложении по морфеме\n",
    "                for i in range(len(morph), 0, -1):\n",
    "#                     print(i, morph[:i] in morph_sentence,morph[:i], morph_sentence)\n",
    "                    if morph[:i] in morph_sentence:\n",
    "                        idx = morph_sentence.index(morph[:i])\n",
    "                        new_roles[srl] = words[idx]\n",
    "                        if srl == 'V':\n",
    "                            srl_verb['verb'] = words[idx]\n",
    "                        break\n",
    "\n",
    "\n",
    "        #     Считаем сколько слов правильно перевели\n",
    "\n",
    "            srl_verb['description'] = new_roles\n",
    "\n",
    "            srl_verb['tags'] = self.get_tags(words, new_roles)\n",
    "\n",
    "            metric.append(len(new_roles.keys()) / len(verb.keys()))\n",
    "            result['verbs'].append(srl_verb)\n",
    "\n",
    "        result['words'] = words\n",
    "        result['metric'] = round(np.mean(metric),2)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def predict(self, tat_sentence, language_ru_name, tries=5):\n",
    "        pred = None\n",
    "        language = self.language_code_dict[language_ru_name]\n",
    "\n",
    "        #перевод\n",
    "        rus_sentence = self.translation(tat_sentence, source_language=language[0])[0]\n",
    "#         print(rus_sentence)\n",
    "        # стемминг слов исходного предложения\n",
    "        stem_input_words = self.get_morph(tat_sentence, language[1])\n",
    "        # получить список словарей лемма - роль\n",
    "        roles = self.get_srl_turkic(rus_sentence, language_ru_name)\n",
    "        # Список слов в предложении\n",
    "        words = tat_sentence.split()\n",
    "\n",
    "        for i in range(tries):\n",
    "            try:\n",
    "                pred = self.get_new_roles(tat_sentence, stem_input_words, roles, words)\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        return pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87017db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'юды.',\n",
       "   'description': {'V': 'юды.', 'Arg(агенс)': 'Әни'},\n",
       "   'tags': ['Arg(агенс)', 'O', 'V', 'O', 'O', 'O']},\n",
       "  {'verb': 'йөртте.',\n",
       "   'description': {'V': 'йөртте.', 'Arg(агенс)': 'Әти'},\n",
       "   'tags': ['O', 'O', 'O', 'Arg(агенс)', 'O', 'V']}],\n",
       " 'words': ['Әни', 'рамны', 'юды.', 'Әти', 'машинаны', 'йөртте.'],\n",
       " 'metric': 0.83}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl = Model_srl2()\n",
    "with open('text_tt.txt', encoding='utf-8') as f:\n",
    "    texts_tt = f.readlines()\n",
    "selected_language = 'татарский'\n",
    "result = srl.predict(texts_tt[2], selected_language)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6af8544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = [{'V': 'юу', 'Arg(агенс)': 'әни', 'Arg(пациенс)': 'кыса'},\n",
    "        {'V': 'йөртү', 'Arg(агенс)': 'әти'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d40f8",
   "metadata": {},
   "source": [
    "# Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d300da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3976909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_news-commentary-v14-wmt19.en-kk_full.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0acf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = Model_srl2()\n",
    "selected_language = 'казахский'\n",
    "res = []\n",
    "#  Проверка что все работает\n",
    "result = srl.predict(df.loc[1,'kk'], selected_language)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5100ec-3973-4b3f-802d-45dae0d2123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[1344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d422a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rukis\\AppData\\Local\\Temp\\ipykernel_1240\\2579236067.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(0, df.shape[0])):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb613285b9de46258c283b1fd523a7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7491 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidJSONError",
     "evalue": "Out of range float values are not JSON compliant",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py:473\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_body\u001b[1;34m(self, data, files, json)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 473\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py:234\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Out of range float values are not JSON compliant",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidJSONError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m----> 2\u001b[0m     srl_labeled \u001b[38;5;241m=\u001b[39m \u001b[43msrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_language\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     res\u001b[38;5;241m.\u001b[39mappend(srl_labeled)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36mModel_srl2.predict\u001b[1;34m(self, tat_sentence, language_ru_name, tries)\u001b[0m\n\u001b[0;32m    164\u001b[0m         language \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanguage_code_dict[language_ru_name]\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;66;03m#перевод\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m         rus_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtat_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_language\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m#         print(rus_sentence)\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;66;03m# стемминг слов исходного предложения\u001b[39;00m\n\u001b[0;32m    170\u001b[0m         stem_input_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_morph(tat_sentence, language[\u001b[38;5;241m1\u001b[39m])\n",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36mModel_srl2.translation\u001b[1;34m(self, texts, source_language, target_language)\u001b[0m\n\u001b[0;32m     23\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(IAM_TOKEN)\n\u001b[0;32m     26\u001b[0m }\n\u001b[0;32m     27\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://translate.api.cloud.yandex.net/translate/v2/translate\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 28\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mОжидаю 0.5 секунды...\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:117\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:515\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[0;32m    504\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[0;32m    505\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[0;32m    514\u001b[0m )\n\u001b[1;32m--> 515\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    519\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[0;32m    520\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[0;32m    521\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:443\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    440\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    442\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[1;32m--> 443\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py:321\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n\u001b[1;32m--> 321\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_auth(auth, url)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# Note that prepare_auth must be last to enable authentication schemes\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# such as OAuth to work on a fully prepared request.\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# This MUST go after prepare_auth. Authenticators could add a hook\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py:475\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_body\u001b[1;34m(self, data, files, json)\u001b[0m\n\u001b[0;32m    473\u001b[0m     body \u001b[38;5;241m=\u001b[39m complexjson\u001b[38;5;241m.\u001b[39mdumps(json, allow_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidJSONError(ve, request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m    478\u001b[0m     body \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mInvalidJSONError\u001b[0m: Out of range float values are not JSON compliant"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, df.shape[0])):\n",
    "    srl_labeled = srl.predict(df.loc[i,'kk'], selected_language)\n",
    "    res.append(srl_labeled)\n",
    "    if i % 500 == 0:\n",
    "        df_res = pd.DataFrame(res)\n",
    "        df_res.to_csv('kk_res.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a356925-e8c9-401d-aff9-75b590af3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = pd.DataFrame(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4823a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for i in range(len(res)):\n",
    "    if df_labeled.loc[i,0] is not None:\n",
    "        metrics.append(df_labeled.loc[i,0]['metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89a06262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5552231604342581"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e40b308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1344"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5eecb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.to_csv(\"kk_res.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d0da44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.to_excel(\"kk_res.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec7467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
