{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53752a4f-6d99-4760-a8db-26ff41e66928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e0ede6-e860-4564-8992-afcda163853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c23a4c7-f1db-4fd6-abbf-ddea196a8bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/IINemo/isanlp_srl_framebank.git\n",
      "  Cloning https://github.com/IINemo/isanlp_srl_framebank.git to c:\\users\\rukis\\appdata\\local\\temp\\pip-req-build-vgydewx1\n",
      "  Resolved https://github.com/IINemo/isanlp_srl_framebank.git to commit 0c7978083911e0e539e9cf7f79e3f863c3876ee8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/IINemo/isanlp_srl_framebank.git 'C:\\Users\\rukis\\AppData\\Local\\Temp\\pip-req-build-vgydewx1'\n",
      "  Running command git submodule update --init --recursive -q\n",
      "  fatal: unable to connect to github.com:\n",
      "  github.com[0: 140.82.121.4]: errno=Unknown error\n",
      "\n",
      "  fatal: clone of 'git://github.com/IINemo/brat.git' into submodule path 'C:/Users/rukis/AppData/Local/Temp/pip-req-build-vgydewx1/docker/demo/brat' failed\n",
      "  Failed to clone 'docker/demo/brat'. Retry scheduled\n",
      "  fatal: unable to connect to github.com:\n",
      "  github.com[0: 140.82.121.4]: errno=Unknown error\n",
      "\n",
      "  fatal: clone of 'git://github.com/IINemo/brat.git' into submodule path 'C:/Users/rukis/AppData/Local/Temp/pip-req-build-vgydewx1/docker/demo/brat' failed\n",
      "  Failed to clone 'docker/demo/brat' a second time, aborting\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  git submodule update --init --recursive -q did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "git submodule update --init --recursive -q did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/IINemo/isanlp_srl_framebank.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf7af7ec-65a5-4b5e-9f0b-2bc7804136c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "from pprint import pprint as print_\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from isanlp_srl_framebank.pipeline_default import PipelineDefault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10265a53-96f2-4704-a115-516e7c090348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.*\n",
      "  Using cached protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "      Successfully uninstalled protobuf-4.21.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Отказано в доступе: 'C:\\\\Users\\\\rukis\\\\anaconda3\\\\Lib\\\\site-packages\\\\google\\\\~upb\\\\_message.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2dce71b-7cb5-479b-b824-5e317ba4eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de29404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   343  100   254  100    89   1316    461 --:--:-- --:--:-- --:--:--  1786\n"
     ]
    }
   ],
   "source": [
    "!curl -d \"{\\\"yandexPassportOauthToken\\\":\\\"y0_AgAAAAAFAhuyAATuwQAAAADTA2uLt9P4wIhIRcycxMNG36QNKa9u_pc\\\"}\" \"https://iam.api.cloud.yandex.net/iam/v1/tokens\" --ssl-no-revoke -o iamToken.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ab5b8cd-836f-4a51-a1f6-970fbc58364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('iamToken.txt') as f:\n",
    "    d = json.loads(f.read())\n",
    "    IAM_TOKEN = d['iamToken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc4d435d-dd7e-4551-bdeb-9d3922761eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t1.9euelZqZjJPOjMnGmMfHj4yOzZLLzO3rnpWam46Pjp6Qj5uam5KQxo_Pxo3l8_ccNXpi-e8MBh4H_d3z91xjd2L57wwGHgf9.q0JdZc5jIWPffN__nS4EP94c_WCt5sLvpRRUrea527rec4Lt_Yf_m8g-PYu1g9dm_S01ZUujx8Qe8_2b0XXOCg'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('folder_id.txt') as f:\n",
    "    folder_id = f.read()\n",
    "IAM_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0645e314-9eb8-48f3-aea0-e39668c6c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run --rm -p 3333:3333 inemo/isanlp\n",
    "# docker run --rm --shm-size=1024m -ti -p 3334:9999 inemo/syntaxnet_rus server 0.0.0.0 9999\n",
    "# docker run --rm -p 3335:3333 inemo/isanlp_srl_framebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a25271b1-4aa5-427a-b82f-ea30a173cf62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from isanlp_srl_framebank.pipeline_default import PipelineDefault  \n",
    "#\n",
    "ppl = PipelineDefault(address_morph=('localhost', 3333),\n",
    "                      address_syntax=('localhost', 3334),\n",
    "                      address_srl=('localhost', 3335))\n",
    "res = ppl('Мы поехали на дачу.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f94b6ca7-3646-4b30-87e8-b80c441494ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "languages = ['tat', 'kaz', 'kir', 'bak', 'uzb'] # языки татарский, казахский, киргизский\n",
    "language = languages[0]\n",
    "url = 'https://beta.apertium.org/index.eng.html#analysis?aLang=' + language + '&aQ='    \n",
    "browser = webdriver.Chrome()\n",
    "browser.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4614738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_srl2:\n",
    "    def __init__(self, RUS_SENTENCE=None):\n",
    "        self.RUS_SENTENCE = RUS_SENTENCE\n",
    "        self.ppl = PipelineDefault(address_morph=('localhost', 3333),\n",
    "                      address_syntax=('localhost', 3334),\n",
    "                      address_srl=('localhost', 3335))\n",
    "        self.language_code_dict =  {\n",
    "        'татарский': ['tt', 'Tatar'],\n",
    "        'казахский' : ['kk', 'Kazakh'],\n",
    "        'башкирский': ['ba', 'Bashqort'],\n",
    "        'киргизский' : ['ky', 'Kyrgyz']\n",
    "        }\n",
    "\n",
    "    def translation(self, texts, source_language='tt', target_language='ru'):\n",
    "        #print('texts', texts)\n",
    "        body = {\n",
    "            \"targetLanguageCode\": target_language,\n",
    "            \"texts\": texts,\n",
    "            \"folderId\": folder_id,\n",
    "            \"sourceLanguageCode\":  source_language\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer {0}\".format(IAM_TOKEN)\n",
    "        }\n",
    "        url = 'https://translate.api.cloud.yandex.net/translate/v2/translate'\n",
    "        response = requests.post(url,\n",
    "            json = body,\n",
    "            headers = headers\n",
    "        )\n",
    "        if response.status_code != 200:\n",
    "            print('Ожидаю 0.5 секунды...')  \n",
    "            time.sleep(0.5)\n",
    "            response = requests.post(url,\n",
    "            json = body,\n",
    "            headers = headers\n",
    "            )\n",
    "        d = json.loads(response.text)\n",
    "        #print(texts, d)\n",
    "        translations = d['translations']\n",
    "#         print([t['text'] for t in translations])\n",
    "        return [t['text'] for t in translations]\n",
    "    \n",
    "    def drop_punkt(self, word):\n",
    "        punc = '''!()-[]{};:\"\\,<>./?@#$%^&*_~'''\n",
    "        for p in punc:\n",
    "            word = word.replace(p,'')\n",
    "        return word\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        words = text.split()\n",
    "        return [self.drop_punkt(word) for word in words]\n",
    "    \n",
    "    def get_morph(self, text, language):\n",
    "        lang_field = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[1]/div/select')\n",
    "        lang_field.send_keys(language)\n",
    "\n",
    "        text_field = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[2]/div/textarea').clear()\n",
    "        text_field = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[2]/div/textarea')\n",
    "\n",
    "        text = self.drop_punkt(text)\n",
    "        text_field.send_keys(text)\n",
    "\n",
    "        button = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[3]/div/button')\n",
    "        button.click()\n",
    "        sleep(1)\n",
    "\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        translation = soup.find_all('td',class_=\"text-left\")\n",
    "        words = []\n",
    "        for word in translation:\n",
    "            word = word.text.split()\n",
    "            for i, w in enumerate(word):\n",
    "                if w == '↤':\n",
    "                    break\n",
    "            word = word[:i]\n",
    "            for w in word:\n",
    "                words.append(w)\n",
    "        return words\n",
    "\n",
    "\n",
    "    def print_roles(self, lemma, role_annot, targetLanguage=None):\n",
    "        roles = []\n",
    "        for sent_num, ann_sent in enumerate(role_annot):\n",
    "            word_role = {}\n",
    "            \n",
    "            for event in ann_sent:\n",
    "#                 print(event.pred)\n",
    "                lemma_pred = lemma[sent_num][event.pred[0]]\n",
    "#                 print(lemma_pred)\n",
    "                if targetLanguage is not None:\n",
    "                    trg_lang = self.language_code_dict[targetLanguage][0]\n",
    "                    src_lang = 'ru'\n",
    "                    #print('=====Pred: {}'.format(self.translation(lemma_pred, src_lang, trg_lang)[0]))\n",
    "                    word_role['V'] = self.translation(lemma_pred, src_lang, trg_lang)\n",
    "                else:\n",
    "                    print('=====Pred: {}'.format(lemma_pred))\n",
    "                for arg in event.args:\n",
    "                    lemma_arg  = lemma[sent_num][arg.begin]\n",
    "                    if targetLanguage is not None:\n",
    "                        #print('Arg({}): {}'.format(arg.tag, self.translation(lemma_arg, src_lang, trg_lang)[0]))\n",
    "                        word_role['Arg({})'.format(arg.tag)] = self.translation(lemma_arg, src_lang, trg_lang)\n",
    "                    else:\n",
    "                        print('Arg({}): {}'.format(arg.tag, lemma_arg))\n",
    "            roles.append(word_role)\n",
    "        return roles\n",
    "    \n",
    "    def get_srl_turkic(self, rus_text, selected_language):\n",
    "        res = ppl(rus_text)\n",
    "        return self.print_roles(res['lemma'], res['srl'], selected_language)\n",
    "        \n",
    "    def get_tags(self, words, srl_verb):\n",
    "        new_tags = []\n",
    "        for word in words:\n",
    "            for srl in srl_verb.keys(): \n",
    "                if self.drop_punkt(word) in srl_verb[srl]:\n",
    "                    role = srl\n",
    "                    break\n",
    "                else:\n",
    "                    role = 'O'\n",
    "            new_tags.append(role)\n",
    "        return new_tags\n",
    "\n",
    "    def get_new_roles(self, tat_sentence, morph_sentence, roles, words):\n",
    "        result = {'verbs': []}\n",
    "        metric = []\n",
    "        for verb in roles:\n",
    "            new_roles = {}\n",
    "            srl_verb = {'verb':''}\n",
    "#             print(verb)\n",
    "            for srl in verb.keys():\n",
    "    #             morph = get_morph(verb[srl], language)[0]\n",
    "                morph = verb[srl][0]\n",
    "#                 print(morph)\n",
    "        #         Ищем слово в предложении по морфеме\n",
    "                for i in range(len(morph), 0, -1):\n",
    "#                     print(i, morph[:i] in morph_sentence,morph[:i], morph_sentence)\n",
    "                    if morph[:i] in morph_sentence:\n",
    "                        idx = morph_sentence.index(morph[:i])\n",
    "                        new_roles[srl] = words[idx]\n",
    "                        if srl == 'V':\n",
    "                            srl_verb['verb'] = words[idx]\n",
    "                        break\n",
    "\n",
    "\n",
    "        #     Считаем сколько слов правильно перевели\n",
    "\n",
    "            srl_verb['description'] = new_roles\n",
    "\n",
    "            srl_verb['tags'] = self.get_tags(words, new_roles)\n",
    "\n",
    "            metric.append(len(new_roles.keys()) / len(verb.keys()))\n",
    "            result['verbs'].append(srl_verb)\n",
    "\n",
    "        result['words'] = words\n",
    "        result['metric'] = round(np.mean(metric),2)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def predict(self, tat_sentence, language_ru_name, tries=5):\n",
    "        pred = None\n",
    "        language = self.language_code_dict[language_ru_name]\n",
    "\n",
    "        #перевод\n",
    "        rus_sentence = self.translation(tat_sentence, source_language=language[0])[0]\n",
    "#         print(rus_sentence)\n",
    "        # стемминг слов исходного предложения\n",
    "        stem_input_words = self.get_morph(tat_sentence, language[1])\n",
    "        # получить список словарей лемма - роль\n",
    "        roles = self.get_srl_turkic(rus_sentence, language_ru_name)\n",
    "        # Список слов в предложении\n",
    "        words = tat_sentence.split()\n",
    "\n",
    "        for i in range(tries):\n",
    "            try:\n",
    "                pred = self.get_new_roles(tat_sentence, stem_input_words, roles, words)\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        return pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87017db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'юды.',\n",
       "   'description': {'V': 'юды.', 'Arg(агенс)': 'Әни'},\n",
       "   'tags': ['Arg(агенс)', 'O', 'V', 'O', 'O', 'O']},\n",
       "  {'verb': 'йөртте.',\n",
       "   'description': {'V': 'йөртте.', 'Arg(агенс)': 'Әти'},\n",
       "   'tags': ['O', 'O', 'O', 'Arg(агенс)', 'O', 'V']}],\n",
       " 'words': ['Әни', 'рамны', 'юды.', 'Әти', 'машинаны', 'йөртте.'],\n",
       " 'metric': 0.83}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl = Model_srl2()\n",
    "with open('text_tt.txt', encoding='utf-8') as f:\n",
    "    texts_tt = f.readlines()\n",
    "selected_language = 'татарский'\n",
    "result = srl.predict(texts_tt[2], selected_language)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6af8544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = [{'V': 'юу', 'Arg(агенс)': 'әни', 'Arg(пациенс)': 'кыса'},\n",
    "        {'V': 'йөртү', 'Arg(агенс)': 'әти'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d40f8",
   "metadata": {},
   "source": [
    "# Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d300da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3976909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_news-commentary-v14-wmt19.en-kk_full.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0acf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = Model_srl2()\n",
    "selected_language = 'казахский'\n",
    "res = []\n",
    "#  Проверка что все работает\n",
    "result = srl.predict(df.loc[1,'kk'], selected_language)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41cabe6f-c1e1-48fb-917f-886fbd6366d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 1345 #+ 2587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d5100ec-3973-4b3f-802d-45dae0d2123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pad:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d422a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rukis\\AppData\\Local\\Temp\\ipykernel_7352\\2945300123.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(pad, df.shape[0])):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefbb017a602425ab0b6bca386da9289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ожидаю 0.5 секунды...\n",
      "Ожидаю 0.5 секунды...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'translations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(pad, df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m----> 2\u001b[0m     srl_labeled \u001b[38;5;241m=\u001b[39m \u001b[43msrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_language\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     res\u001b[38;5;241m.\u001b[39mappend(srl_labeled)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mModel_srl2.predict\u001b[1;34m(self, tat_sentence, language_ru_name, tries)\u001b[0m\n\u001b[0;32m    170\u001b[0m stem_input_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_morph(tat_sentence, language[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# получить список словарей лемма - роль\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m roles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_srl_turkic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrus_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage_ru_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Список слов в предложении\u001b[39;00m\n\u001b[0;32m    174\u001b[0m words \u001b[38;5;241m=\u001b[39m tat_sentence\u001b[38;5;241m.\u001b[39msplit()\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mModel_srl2.get_srl_turkic\u001b[1;34m(self, rus_text, selected_language)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_srl_turkic\u001b[39m(\u001b[38;5;28mself\u001b[39m, rus_text, selected_language):\n\u001b[0;32m    111\u001b[0m     res \u001b[38;5;241m=\u001b[39m ppl(rus_text)\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_roles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlemma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msrl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_language\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mModel_srl2.print_roles\u001b[1;34m(self, lemma, role_annot, targetLanguage)\u001b[0m\n\u001b[0;32m     95\u001b[0m     src_lang \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mru\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m#print('=====Pred: {}'.format(self.translation(lemma_pred, src_lang, trg_lang)[0]))\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     word_role[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlemma_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg_lang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=====Pred: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(lemma_pred))\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mModel_srl2.translation\u001b[1;34m(self, texts, source_language, target_language)\u001b[0m\n\u001b[0;32m     39\u001b[0m         d \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;66;03m#print(texts, d)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m         translations \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranslations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#         print([t['text'] for t in translations])\u001b[39;00m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m translations]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'translations'"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(pad, df.shape[0])):\n",
    "    srl_labeled = srl.predict(df.loc[i,'kk'], selected_language)\n",
    "    res.append(srl_labeled)\n",
    "    if i % 500 == 0:\n",
    "        df_res = pd.DataFrame(res)\n",
    "        df_res.to_csv('kk_res.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "454952ca-0ed4-4500-9737-9ce16e1cd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(df_labeled, df_sentence, language):\n",
    "    df_labeled = df_labeled.fillna('')\n",
    "    df_sent_copy = df_sentence.copy().reset_index().loc[:,language]\n",
    "    metrics = []\n",
    "    for i in range(df_labeled.shape[0]):\n",
    "        try:\n",
    "            metrics.append(ast.literal_eval(df_labeled.loc[i,'0'])['metric'])\n",
    "\n",
    "        except:\n",
    "            metrics.append(0)\n",
    "    df_labeled.columns = ['srl'+ language]\n",
    "    df_labeled['metric'] = pd.Series(metrics)\n",
    "    df_labeled['sentence'] = df_sent_copy.iloc[:df_labeled.shape[0]]\n",
    "    return df_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b02a6-00bf-4cfa-bba8-df854f601365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a356925-e8c9-401d-aff9-75b590af3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_kk3 = pd.DataFrame(res)\n",
    "m_kk3 = get_datasets(df_labeled_kk3, df.loc[:,'kk'], 'kk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "549bbffa-59e7-4f8b-8597-a4ac39aadbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srlkk</th>\n",
       "      <th>metric</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Бұл – тек дамушы елдердің ғана басында бар про...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'verbs': [{'verb': 'жазып', 'description': {'...</td>\n",
       "      <td>0</td>\n",
       "      <td>Қазанның 16-сында жемқорлық туралы әшкерелеуші...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'verbs': [{'verb': '', 'description': {'Arg(к...</td>\n",
       "      <td>0</td>\n",
       "      <td>Оған қастандық жасаған үш адамға ресми айып та...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'verbs': [{'verb': 'байланысты', 'description...</td>\n",
       "      <td>0</td>\n",
       "      <td>Мальта сияқты Еуропа одағына мүше ел – Словаки...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'verbs': [{'verb': '', 'description': {'Arg(п...</td>\n",
       "      <td>0</td>\n",
       "      <td>Полиция бұл іс бойынша бірнеше адамды тұтқында...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>{'verbs': [{'verb': 'ісі', 'description': {'V'...</td>\n",
       "      <td>0</td>\n",
       "      <td>Кейбір түсіндірмелер бойынша, Трамптың бос сөз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>{'verbs': [{'verb': '', 'description': {'Arg(с...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ең жоғары ықтимал деңгейге қорқыныш сезімін кө...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>{'verbs': [{'verb': 'мүмкін.', 'description': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Герман Геринг Екінші дүниежүзілік соғыстан кей...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Бұл оңай.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>{'verbs': [{'verb': '', 'description': {'Arg(а...</td>\n",
       "      <td>0</td>\n",
       "      <td>Сізге бар керегі оларға шабуыл жасалып жатқаны...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4551 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  srlkk  metric  \\\n",
       "0                                                             0   \n",
       "1     {'verbs': [{'verb': 'жазып', 'description': {'...       0   \n",
       "2     {'verbs': [{'verb': '', 'description': {'Arg(к...       0   \n",
       "3     {'verbs': [{'verb': 'байланысты', 'description...       0   \n",
       "4     {'verbs': [{'verb': '', 'description': {'Arg(п...       0   \n",
       "...                                                 ...     ...   \n",
       "4546  {'verbs': [{'verb': 'ісі', 'description': {'V'...       0   \n",
       "4547  {'verbs': [{'verb': '', 'description': {'Arg(с...       0   \n",
       "4548  {'verbs': [{'verb': 'мүмкін.', 'description': ...       0   \n",
       "4549                                                          0   \n",
       "4550  {'verbs': [{'verb': '', 'description': {'Arg(а...       0   \n",
       "\n",
       "                                               sentence  \n",
       "0     Бұл – тек дамушы елдердің ғана басында бар про...  \n",
       "1     Қазанның 16-сында жемқорлық туралы әшкерелеуші...  \n",
       "2     Оған қастандық жасаған үш адамға ресми айып та...  \n",
       "3     Мальта сияқты Еуропа одағына мүше ел – Словаки...  \n",
       "4     Полиция бұл іс бойынша бірнеше адамды тұтқында...  \n",
       "...                                                 ...  \n",
       "4546  Кейбір түсіндірмелер бойынша, Трамптың бос сөз...  \n",
       "4547  Ең жоғары ықтимал деңгейге қорқыныш сезімін кө...  \n",
       "4548  Герман Геринг Екінші дүниежүзілік соғыстан кей...  \n",
       "4549                                          Бұл оңай.  \n",
       "4550  Сізге бар керегі оларға шабуыл жасалып жатқаны...  \n",
       "\n",
       "[4551 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_kk3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4823a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for i in range(len(res)):\n",
    "    if df_labeled_kk3.loc[i,0] is not None:\n",
    "        metrics.append(df_labeled_kk3.loc[i,0]['metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89a06262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5601697976878613"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e40b308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4551"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5eecb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_kk3.to_csv(\"kk_res_3_large.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0da44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_kk3.to_excel(\"kk_res_3_large.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3aec7467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_kk3.to_csv(\"kk_res_3_1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3363fdba-14e9-40ca-93ed-1bba8c0f6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_kk3.to_excel(\"kk_res_3_1.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa2576-3854-4c05-9c63-a35cd166abc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "made-py39-venv",
   "language": "python",
   "name": "made-py39-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
