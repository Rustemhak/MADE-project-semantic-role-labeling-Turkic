{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53752a4f-6d99-4760-a8db-26ff41e66928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e0ede6-e860-4564-8992-afcda163853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7af7ec-65a5-4b5e-9f0b-2bc7804136c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "from pprint import pprint as print_\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from isanlp_srl_framebank.pipeline_default import PipelineDefault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2dce71b-7cb5-479b-b824-5e317ba4eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de29404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   343  100   254  100    89    708    248 --:--:-- --:--:-- --:--:--   963\n"
     ]
    }
   ],
   "source": [
    "!curl -d \"{\\\"yandexPassportOauthToken\\\":\\\"y0_AgAAAAAFAhuyAATuwQAAAADTA2uLt9P4wIhIRcycxMNG36QNKa9u_pc\\\"}\" \"https://iam.api.cloud.yandex.net/iam/v1/tokens\" --ssl-no-revoke -o iamToken.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ab5b8cd-836f-4a51-a1f6-970fbc58364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('iamToken.txt') as f:\n",
    "    d = json.loads(f.read())\n",
    "    IAM_TOKEN = d['iamToken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc4d435d-dd7e-4551-bdeb-9d3922761eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t1.9euelZrPnZmbjcyRz46Vl5TIxozNnu3rnpWam46Pjp6Qj5uam5KQxo_Pxo3l8_cuBwBj-e8tWVZy_N3z9241fWL57y1ZVnL8.yDRGm9fmWHHLIQ3_WuL_6kwEdO7kvWg9zIlCbFNdYIjcWv4EBTmpdXLMAo2peybZfyMQ_95YNenHAbJHAuj6AA'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IAM_TOKEN = 't1.9euelZqaz5DGjI6Py5bLnoqTlo_Oju3rnpWaj46Nkc6ejZaLyZvOmZqWj53l8_dIF2Zk-e9eDic9_t3z9whGY2T5714OJz3-.1UJE5innTD10cDR2-7YbCzvwem5VKOvoIQCksQwLbJAA7oAdm4OpX9lgQyC6cosbkLvAMqxKaFT1SfQlDXTlBg'\n",
    "folder_id = 'b1gs2kplab3ve997i80t'\n",
    "IAM_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0645e314-9eb8-48f3-aea0-e39668c6c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run --rm -p 3333:3333 inemo/isanlp\n",
    "# docker run --rm --shm-size=1024m -ti -p 3334:9999 inemo/syntaxnet_rus server 0.0.0.0 9999\n",
    "# docker run --rm -p 3335:3333 inemo/isanlp_srl_framebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a25271b1-4aa5-427a-b82f-ea30a173cf62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from isanlp_srl_framebank.pipeline_default import PipelineDefault  \n",
    "#\n",
    "ppl = PipelineDefault(address_morph=('localhost', 3333),\n",
    "                      address_syntax=('localhost', 3334),\n",
    "                      address_srl=('localhost', 3335))\n",
    "res = ppl('Мы поехали на дачу.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f94b6ca7-3646-4b30-87e8-b80c441494ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 156 ms\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "languages = ['tat', 'kaz', 'kir', 'bak', 'uzb'] # языки татарский, казахский, киргизский\n",
    "language = languages[0]\n",
    "url = 'https://beta.apertium.org/index.eng.html#analysis?aLang=' + language + '&aQ='    \n",
    "browser = webdriver.Chrome()\n",
    "browser.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4614738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_srl2:\n",
    "    def __init__(self, RUS_SENTENCE=None):\n",
    "        self.RUS_SENTENCE = RUS_SENTENCE\n",
    "        self.ppl = PipelineDefault(address_morph=('localhost', 3333),\n",
    "                      address_syntax=('localhost', 3334),\n",
    "                      address_srl=('localhost', 3335))\n",
    "        self.language_code_dict =  {\n",
    "        'татарский': ['tt', 'Tatar'],\n",
    "        'казахский' : ['kk', 'Kazakh'],\n",
    "        'башкирский': ['ba', 'Bashqort'],\n",
    "        'киргизский' : ['ky', 'Kyrgyz']\n",
    "        }\n",
    "\n",
    "    def translation(self, texts, source_language='tt', target_language='ru'):\n",
    "        #print('texts', texts)\n",
    "        body = {\n",
    "            \"targetLanguageCode\": target_language,\n",
    "            \"texts\": texts,\n",
    "            \"folderId\": folder_id,\n",
    "            \"sourceLanguageCode\":  source_language\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer {0}\".format(IAM_TOKEN)\n",
    "        }\n",
    "        url = 'https://translate.api.cloud.yandex.net/translate/v2/translate'\n",
    "        response = requests.post(url,\n",
    "            json = body,\n",
    "            headers = headers\n",
    "        )\n",
    "        if response.status_code != 200:\n",
    "            print('Ожидаю 0.5 секунды...')  \n",
    "            time.sleep(0.5)\n",
    "            response = requests.post(url,\n",
    "            json = body,\n",
    "            headers = headers\n",
    "            )\n",
    "        d = json.loads(response.text)\n",
    "        #print(texts, d)\n",
    "        translations = d['translations']\n",
    "#         print([t['text'] for t in translations])\n",
    "        return [t['text'] for t in translations]\n",
    "    \n",
    "    def drop_punkt(self, word):\n",
    "        punc = '''!()-[]{};:\"\\,<>./?@#$%^&*_~'''\n",
    "        for p in punc:\n",
    "            word = word.replace(p,'')\n",
    "        return word\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        words = text.split()\n",
    "        return [self.drop_punkt(word) for word in words]\n",
    "    \n",
    "    def get_morph(self, text, language):\n",
    "        lang_field = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[1]/div/select')\n",
    "        lang_field.send_keys(language)\n",
    "\n",
    "        text_field = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[2]/div/textarea').clear()\n",
    "        text_field = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[2]/div/textarea')\n",
    "\n",
    "        text = self.drop_punkt(text)\n",
    "        text_field.send_keys(text)\n",
    "\n",
    "        button = browser.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form/div[3]/div/button')\n",
    "        button.click()\n",
    "        sleep(1)\n",
    "\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        translation = soup.find_all('td',class_=\"text-left\")\n",
    "        words = []\n",
    "        for word in translation:\n",
    "            word = word.text.split()\n",
    "            for i, w in enumerate(word):\n",
    "                if w == '↤':\n",
    "                    break\n",
    "            word = word[:i]\n",
    "            for w in word:\n",
    "                words.append(w)\n",
    "        return words\n",
    "\n",
    "\n",
    "    def print_roles(self, lemma, role_annot, targetLanguage=None):\n",
    "        roles = []\n",
    "        for sent_num, ann_sent in enumerate(role_annot):\n",
    "            word_role = {}\n",
    "            \n",
    "            for event in ann_sent:\n",
    "#                 print(event.pred)\n",
    "                lemma_pred = lemma[sent_num][event.pred[0]]\n",
    "#                 print(lemma_pred)\n",
    "                if targetLanguage is not None:\n",
    "                    trg_lang = self.language_code_dict[targetLanguage][0]\n",
    "                    src_lang = 'ru'\n",
    "                    #print('=====Pred: {}'.format(self.translation(lemma_pred, src_lang, trg_lang)[0]))\n",
    "                    word_role['V'] = self.translation(lemma_pred, src_lang, trg_lang)\n",
    "                else:\n",
    "                    print('=====Pred: {}'.format(lemma_pred))\n",
    "                for arg in event.args:\n",
    "                    lemma_arg  = lemma[sent_num][arg.begin]\n",
    "                    if targetLanguage is not None:\n",
    "                        #print('Arg({}): {}'.format(arg.tag, self.translation(lemma_arg, src_lang, trg_lang)[0]))\n",
    "                        word_role['Arg({})'.format(arg.tag)] = self.translation(lemma_arg, src_lang, trg_lang)\n",
    "                    else:\n",
    "                        print('Arg({}): {}'.format(arg.tag, lemma_arg))\n",
    "            roles.append(word_role)\n",
    "        return roles\n",
    "    \n",
    "    def get_srl_turkic(self, rus_text, selected_language):\n",
    "        res = ppl(rus_text)\n",
    "        return self.print_roles(res['lemma'], res['srl'], selected_language)\n",
    "        \n",
    "    def get_tags(self, words, srl_verb):\n",
    "        new_tags = []\n",
    "        for word in words:\n",
    "            for srl in srl_verb.keys(): \n",
    "                if self.drop_punkt(word) in srl_verb[srl]:\n",
    "                    role = srl\n",
    "                    break\n",
    "                else:\n",
    "                    role = 'O'\n",
    "            new_tags.append(role)\n",
    "        return new_tags\n",
    "\n",
    "    def get_new_roles(self, tat_sentence, morph_sentence, roles, words):\n",
    "        result = {'verbs': []}\n",
    "        metric = []\n",
    "        for verb in roles:\n",
    "            new_roles = {}\n",
    "            srl_verb = {'verb':''}\n",
    "#             print(verb)\n",
    "            for srl in verb.keys():\n",
    "    #             morph = get_morph(verb[srl], language)[0]\n",
    "                morph = verb[srl][0]\n",
    "#                 print(morph)\n",
    "        #         Ищем слово в предложении по морфеме\n",
    "                for i in range(len(morph), 0, -1):\n",
    "#                     print(i, morph[:i] in morph_sentence,morph[:i], morph_sentence)\n",
    "                    if morph[:i] in morph_sentence:\n",
    "                        idx = morph_sentence.index(morph[:i])\n",
    "                        new_roles[srl] = words[idx]\n",
    "                        if srl == 'V':\n",
    "                            srl_verb['verb'] = words[idx]\n",
    "                        break\n",
    "\n",
    "\n",
    "        #     Считаем сколько слов правильно перевели\n",
    "\n",
    "            srl_verb['description'] = new_roles\n",
    "\n",
    "            srl_verb['tags'] = self.get_tags(words, new_roles)\n",
    "\n",
    "            metric.append(len(new_roles.keys()) / len(verb.keys()))\n",
    "            result['verbs'].append(srl_verb)\n",
    "\n",
    "        result['words'] = words\n",
    "        result['metric'] = round(np.mean(metric),2)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def predict(self, tat_sentence, language_ru_name, tries=5):\n",
    "        pred = None\n",
    "        language = self.language_code_dict[language_ru_name]\n",
    "\n",
    "        #перевод\n",
    "        rus_sentence = self.translation(tat_sentence, source_language=language[0])[0]\n",
    "#         print(rus_sentence)\n",
    "        # стемминг слов исходного предложения\n",
    "        stem_input_words = self.get_morph(tat_sentence, language[1])\n",
    "        # получить список словарей лемма - роль\n",
    "        roles = self.get_srl_turkic(rus_sentence, language_ru_name)\n",
    "        # Список слов в предложении\n",
    "        words = tat_sentence.split()\n",
    "\n",
    "        for i in range(tries):\n",
    "            try:\n",
    "                pred = self.get_new_roles(tat_sentence, stem_input_words, roles, words)\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        return pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "87017db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'юды.',\n",
       "   'description': {'V': 'юды.', 'Arg(агенс)': 'Әни'},\n",
       "   'tags': ['Arg(агенс)', 'O', 'V', 'O', 'O', 'O']},\n",
       "  {'verb': 'йөртте.',\n",
       "   'description': {'V': 'йөртте.', 'Arg(агенс)': 'Әти'},\n",
       "   'tags': ['O', 'O', 'O', 'Arg(агенс)', 'O', 'V']}],\n",
       " 'words': ['Әни', 'рамны', 'юды.', 'Әти', 'машинаны', 'йөртте.'],\n",
       " 'metric': 0.83}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl = Model_srl2()\n",
    "with open('text_tt.txt', encoding='utf-8') as f:\n",
    "    texts_tt = f.readlines()\n",
    "selected_language = 'татарский'\n",
    "result = srl.predict(texts_tt[2], selected_language)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6af8544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = [{'V': 'юу', 'Arg(агенс)': 'әни', 'Arg(пациенс)': 'кыса'},\n",
    "        {'V': 'йөртү', 'Arg(агенс)': 'әти'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d40f8",
   "metadata": {},
   "source": [
    "# Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d300da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e3976909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/dataset_news-commentary-v14-wmt19.en-kk_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c0acf335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': '',\n",
       "   'description': {'Arg(эталон)': 'Моның',\n",
       "    'Arg(содержание действия)': 'берәр'},\n",
       "   'tags': ['Arg(эталон)', 'O', 'Arg(содержание действия)', 'O', 'O', 'O']}],\n",
       " 'words': ['Моның', 'белән', 'берәр', 'нәрсә', 'эшләп', 'буламы?'],\n",
       " 'metric': 0.67}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl = Model_srl2()\n",
    "selected_language = 'татарский'\n",
    "res = []\n",
    "#  Проверка что все работает\n",
    "result = srl.predict(df.loc[143,'tt'], selected_language)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d422a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arman\\AppData\\Local\\Temp\\ipykernel_7756\\3235040539.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(143, df.shape[0])):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32c93c476334ed88d32f583cf5a840a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(0, df.shape[0])):\n",
    "    srl_labeled = srl.predict(df.loc[i,'tt'], selected_language)\n",
    "    res.append(srl_labeled)\n",
    "    if i % 500 == 0:\n",
    "        df_res = pd.DataFrame(res)\n",
    "        df_res.to_csv('tt_res.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "e4823a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for i in range(len(res)):\n",
    "    if df_labeled.loc[i,0] is not None:\n",
    "        metrics.append(df_labeled.loc[i,0]['metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "89a06262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5765217391304348"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "5e40b308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eecb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da44c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec7467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
